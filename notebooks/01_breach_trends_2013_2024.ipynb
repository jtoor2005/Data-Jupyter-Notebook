{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb4abd3",
   "metadata": {},
   "source": [
    "\n",
    "# Analyzing Data Breach Trends Over Time (2013–2024)\n",
    "\n",
    "This notebook performs an end-to-end analysis of publicly reported data breaches from **2013–2024**.\n",
    "\n",
    "**What you'll see:**\n",
    "- Data cleaning & validation\n",
    "- Yearly trend analysis\n",
    "- Industry × Attack Vector heatmap\n",
    "- Severity classification from `records_exposed`\n",
    "- *(Optional)* simple ML to predict severity from features\n",
    "\n",
    "> If `data/breaches.csv` is empty or missing rows, we'll generate a small **synthetic sample** to demonstrate the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import os, math, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from src.utils import ensure_schema, classify_severity\n",
    "\n",
    "DATA_PATH = Path('../data/breaches.csv')\n",
    "FIG_DIR = Path('../figures')\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0593875",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load CSV\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "df = ensure_schema(df)\n",
    "\n",
    "# If dataset seems empty, create a synthetic sample to make the notebook runnable.\n",
    "if df.dropna(how='all').empty or len(df) < 100:\n",
    "    rng = np.random.default_rng(42)\n",
    "    years = np.arange(2013, 2025)\n",
    "    industries = [\"Healthcare\", \"Financial\", \"Public Sector\", \"Retail\", \"Technology\", \"Education\"]\n",
    "    vectors = [\"Phishing\", \"Ransomware\", \"Web App\", \"Insider\", \"Lost/Stolen\", \"Misconfiguration\"]\n",
    "\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        n = rng.integers(50, 120)  # incidents per year\n",
    "        for _ in range(int(n)):\n",
    "            ind = rng.choice(industries)\n",
    "            vec = rng.choice(vectors, p=[0.22,0.18,0.25,0.10,0.12,0.13])  # rough priors\n",
    "            # records exposed grows slightly over time with heavy tail\n",
    "            base = max(1, (y - 2012)) * 1000\n",
    "            exp = int(abs(rng.lognormal(mean=math.log(base), sigma=1.0)))\n",
    "            rows.append((y, ind, vec, exp, rng.choice([\"Small\",\"Medium\",\"Large\"]), rng.choice([\"US\",\"CA\",\"UK\",\"EU\",\"IN\"])))\n",
    "    df = pd.DataFrame(rows, columns=[\"year\",\"industry\",\"attack_vector\",\"records_exposed\",\"org_size\",\"country\"])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cfb55",
   "metadata": {},
   "source": [
    "## 2) Clean & basic validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep only 2013–2024\n",
    "df = df[(df['year'] >= 2013) & (df['year'] <= 2024)].copy()\n",
    "\n",
    "# Drop rows missing critical fields\n",
    "df = df.dropna(subset=['year','industry','attack_vector','records_exposed'])\n",
    "\n",
    "# Add severity\n",
    "df['severity'] = df['records_exposed'].apply(classify_severity)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Years:\", int(df['year'].min()), \"to\", int(df['year'].max()))\n",
    "print(\"Industries:\", df['industry'].nunique(), \"| Attack vectors:\", df['attack_vector'].nunique())\n",
    "df.sample(5, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf116d",
   "metadata": {},
   "source": [
    "## 3) Yearly trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yearly = df.groupby('year', as_index=False).agg(\n",
    "    incidents=('year','count'),\n",
    "    total_records=('records_exposed','sum'),\n",
    "    median_records=('records_exposed','median')\n",
    ")\n",
    "\n",
    "display(yearly.head())\n",
    "\n",
    "# Plot incidents per year\n",
    "plt.figure()\n",
    "plt.plot(yearly['year'], yearly['incidents'], marker='o')\n",
    "plt.title('Incidents per Year (2013–2024)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'incidents_per_year.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Plot records exposed per year (log scale for readability)\n",
    "plt.figure()\n",
    "plt.plot(yearly['year'], yearly['total_records'], marker='o')\n",
    "plt.title('Total Records Exposed per Year (2013–2024)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Records Exposed (log scale)')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, which='both', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'records_per_year.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394368c",
   "metadata": {},
   "source": [
    "## 4) Industry × Attack Vector heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pivot = (df\n",
    "         .groupby(['industry','attack_vector'])\n",
    "         .size()\n",
    "         .reset_index(name='count')\n",
    "         .pivot(index='industry', columns='attack_vector', values='count')\n",
    "         .fillna(0))\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(pivot, annot=True, fmt='.0f')\n",
    "plt.title('Incidents by Industry × Attack Vector (2013–2024)')\n",
    "plt.xlabel('Attack Vector')\n",
    "plt.ylabel('Industry')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'industry_attack_heatmap.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e570983",
   "metadata": {},
   "source": [
    "## 5) Severity distribution and top categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Severity counts\n",
    "sev_counts = df['severity'].value_counts().reindex(['Low','Medium','High','Critical']).fillna(0)\n",
    "display(sev_counts)\n",
    "\n",
    "plt.figure()\n",
    "sev_counts.plot(kind='bar')\n",
    "plt.title('Severity Distribution')\n",
    "plt.xlabel('Severity')\n",
    "plt.ylabel('Incidents')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'severity_distribution.png', dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Top industries and attack vectors by median severity (proxied by records)\n",
    "by_industry = df.groupby('industry')['records_exposed'].median().sort_values(ascending=False).head(10)\n",
    "by_vector = df.groupby('attack_vector')['records_exposed'].median().sort_values(ascending=False).head(10)\n",
    "\n",
    "display(by_industry, by_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d393c00",
   "metadata": {},
   "source": [
    "## 6) (Optional) Simple ML: Predict severity from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33079e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Encode target as ordinal: Low < Medium < High < Critical\n",
    "order = {'Low':0,'Medium':1,'High':2,'Critical':3}\n",
    "df_ml = df[df['severity'].isin(order)].copy()\n",
    "df_ml['severity_label'] = df_ml['severity'].map(order)\n",
    "\n",
    "X = df_ml[['industry','attack_vector','org_size','country']].fillna('Unknown')\n",
    "y = df_ml['severity_label']\n",
    "\n",
    "categorical = list(X.columns)\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical)]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[('pre', pre),\n",
    "                     ('lr', LogisticRegression(max_iter=200, multi_class='auto'))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred, target_names=['Low','Medium','High','Critical']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa841d93",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Takeaways (edit these after reviewing your actual data)\n",
    "\n",
    "- Incidents show a (fill in) trend from 2013 to 2024.\n",
    "- The most frequent attack vectors are (fill in), with notable spikes in (years).\n",
    "- Industries most impacted include (fill in) driven by (vectors).\n",
    "- Median records exposed indicate higher severity for (categories).\n",
    "- The simple ML baseline achieves (X%) macro-F1; feature engineering could improve this.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
